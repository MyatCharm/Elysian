{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8Bbjir8_z4Td"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/IMDB Dataset.csv')"
      ],
      "metadata": {
        "id": "foN-9G8q2L1G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sampling"
      ],
      "metadata": {
        "id": "rzxxL97_4Kr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_size = 5000"
      ],
      "metadata": {
        "id": "mNxZHyY63KAP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(df, train_size=int(sample_size*0.8), test_size=int(sample_size*0.2), random_state=42)"
      ],
      "metadata": {
        "id": "SV6W4dly3Z5d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleansing"
      ],
      "metadata": {
        "id": "68QtRr2u4Ipt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "jTcqNEiA4L9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "CiKog4Ql5IbF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop = stopwords.words('english')"
      ],
      "metadata": {
        "id": "Pbi3-0zF5MJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from nltk.stem import PorterStemmer\n",
        "porter = PorterStemmer()"
      ],
      "metadata": {
        "id": "y8rt5yLZ5Pw2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions\n",
        "import contractions"
      ],
      "metadata": {
        "id": "2YmOSXBS5U61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspellchecker\n",
        "from spellchecker import SpellChecker\n",
        "spell_checker = SpellChecker()"
      ],
      "metadata": {
        "id": "upeT5A2N5blD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import re"
      ],
      "metadata": {
        "id": "U5X64LDP5i64"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji\n",
        "import emoji\n",
        "import re"
      ],
      "metadata": {
        "id": "00b9TD875lgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['review'] = train_data['review'].apply(lambda x: x.lower())\n",
        "\n",
        "def remove_special_characters_and_numbers(text):\n",
        "    return ''.join(e for e in text if e.isalnum() or e.isspace())\n",
        "\n",
        "train_data['review'] = train_data['review'].apply(lambda x: remove_special_characters_and_numbers(x))\n",
        "\n",
        "def tokenize_word(text):\n",
        "  return word_tokenize(text)\n",
        "\n",
        "train_data['review'] = train_data['review'].apply(lambda x: tokenize_word(x))\n",
        "\n",
        "def stem_text(text):\n",
        "\n",
        "    stemmed_text = ' '.join(porter.stem(token) for token in word_tokenize(str(text)))\n",
        "    return stemmed_text\n",
        "\n",
        "train_data['review'] = train_data['review'].apply(lambda x: stem_text(x))\n",
        "\n",
        "def expand_contractions(text):\n",
        "    expanded_text = contractions.fix(text)\n",
        "    return expanded_text\n",
        "\n",
        "train_data['review'] = train_data['review'].apply(lambda x: expand_contractions(x))\n",
        "\n",
        "#def spell_check(text):\n",
        "\n",
        "    #tokens = text.split()\n",
        "    #misspelled = spell_checker.unknown(tokens)\n",
        "\n",
        "    #for word in misspelled:\n",
        "        #correction = spell_checker.correction(word)\n",
        "        #if correction:\n",
        "            #text = text.replace(word, correction)\n",
        "\n",
        "    #return text\n",
        "\n",
        "#train_data['review'] = train_data['review'].apply(lambda x: spell_check(x))\n",
        "\n",
        "def remove_html_tags(text):\n",
        "    soup = BeautifulSoup(text, 'html.parser')\n",
        "    cleaned_text = soup.get_text(separator=' ')\n",
        "    return cleaned_text\n",
        "\n",
        "def remove_urls(text):\n",
        "    return re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
        "\n",
        "train_data['cleaned_review'] = train_data['review'].apply(remove_html_tags)\n",
        "train_data['review'] = train_data['cleaned_review'].apply(remove_urls)\n",
        "\n",
        "def remove_emojis(text):\n",
        "    return emoji.demojize(text)\n",
        "\n",
        "def remove_special_symbols(text):\n",
        "    return re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "\n",
        "train_data['cleaned_review'] = train_data['review'].apply(remove_emojis)\n",
        "train_data['review'] = train_data['cleaned_review'].apply(remove_special_symbols)"
      ],
      "metadata": {
        "id": "kfybMBqI5roq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['review'] = test_data['review'].apply(lambda x: x.lower())\n",
        "\n",
        "def remove_special_characters_and_numbers(text):\n",
        "    return ''.join(e for e in text if e.isalnum() or e.isspace())\n",
        "\n",
        "test_data['review'] = test_data['review'].apply(lambda x: remove_special_characters_and_numbers(x))\n",
        "\n",
        "def tokenize_word(text):\n",
        "  return word_tokenize(text)\n",
        "\n",
        "test_data['review'] = test_data['review'].apply(lambda x: tokenize_word(x))\n",
        "\n",
        "def stem_text(text):\n",
        "\n",
        "    stemmed_text = ' '.join(porter.stem(token) for token in word_tokenize(str(text)))\n",
        "    return stemmed_text\n",
        "\n",
        "test_data['review'] = test_data['review'].apply(lambda x: stem_text(x))\n",
        "\n",
        "def expand_contractions(text):\n",
        "    expanded_text = contractions.fix(text)\n",
        "    return expanded_text\n",
        "\n",
        "test_data['review'] = test_data['review'].apply(lambda x: expand_contractions(x))\n",
        "\n",
        "#def spell_check(text):\n",
        "\n",
        "    #tokens = text.split()\n",
        "    #misspelled = spell_checker.unknown(tokens)\n",
        "\n",
        "    #for word in misspelled:\n",
        "        #correction = spell_checker.correction(word)\n",
        "        #if correction:\n",
        "            #text = text.replace(word, correction)\n",
        "\n",
        "    #return text\n",
        "\n",
        "#test_data['review'] = test_data['review'].apply(lambda x: spell_check(x))\n",
        "\n",
        "def remove_html_tags(text):\n",
        "    soup = BeautifulSoup(text, 'html.parser')\n",
        "    cleaned_text = soup.get_text(separator=' ')\n",
        "    return cleaned_text\n",
        "\n",
        "def remove_urls(text):\n",
        "    return re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
        "\n",
        "test_data['cleaned_review'] = test_data['review'].apply(remove_html_tags)\n",
        "test_data['review'] = test_data['cleaned_review'].apply(remove_urls)\n",
        "\n",
        "def remove_emojis(text):\n",
        "    return emoji.demojize(text)\n",
        "\n",
        "def remove_special_symbols(text):\n",
        "    return re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "\n",
        "test_data['cleaned_review'] = test_data['review'].apply(remove_emojis)\n",
        "test_data['review'] = test_data['cleaned_review'].apply(remove_special_symbols)"
      ],
      "metadata": {
        "id": "qq76Q4rGFQXx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Splitting"
      ],
      "metadata": {
        "id": "Mb_iYju0FcI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data['review']\n",
        "\n",
        "y_train = train_data['sentiment']"
      ],
      "metadata": {
        "id": "rZH9iWBMFeNY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_data['review']\n",
        "\n",
        "y_test = test_data['sentiment']"
      ],
      "metadata": {
        "id": "ZKI8rV2pFuZV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "II1E9jN5F9kk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CountVectorizer"
      ],
      "metadata": {
        "id": "iPQgtUyeGUb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline1 = Pipeline([\n",
        "    (\"vec\", CountVectorizer()),\n",
        "    (\"lr\", LogisticRegression())\n",
        "])\n",
        "\n",
        "pipeline1.fit(X_train, y_train)\n",
        "\n",
        "y1_pred = pipeline1.predict(X_test)\n",
        "\n",
        "print('accuracy_score', accuracy_score(y_test, y1_pred))\n",
        "print('\\n')\n",
        "\n",
        "print('confusion_matrix\\n',confusion_matrix(y_test, y1_pred))\n",
        "\n",
        "print('\\nclassification_report\\n',classification_report(y_test, y1_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDTPGdP7GU4I",
        "outputId": "10091eb9-41bc-4ff0-bfcd-781089d9541c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy_score 0.845\n",
            "\n",
            "\n",
            "confusion_matrix\n",
            " [[448  76]\n",
            " [ 79 397]]\n",
            "\n",
            "classification_report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.85      0.85      0.85       524\n",
            "    positive       0.84      0.83      0.84       476\n",
            "\n",
            "    accuracy                           0.84      1000\n",
            "   macro avg       0.84      0.84      0.84      1000\n",
            "weighted avg       0.84      0.84      0.84      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF Vectorizer"
      ],
      "metadata": {
        "id": "g5NrFl_yHl63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline2 = Pipeline([\n",
        "    (\"vec\", TfidfVectorizer()),\n",
        "    (\"lr\", LogisticRegression())\n",
        "])\n",
        "\n",
        "pipeline2.fit(X_train, y_train)\n",
        "\n",
        "y2_pred = pipeline2.predict(X_test)\n",
        "\n",
        "print('accuracy_score', accuracy_score(y_test, y2_pred))\n",
        "print('\\n')\n",
        "\n",
        "print('confusion_matrix\\n',confusion_matrix(y_test, y2_pred))\n",
        "\n",
        "print('\\nclassification_report\\n',classification_report(y_test, y2_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILg3WaQvHmVi",
        "outputId": "9e7117e4-68ed-48e8-db4d-3f490256f05d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy_score 0.854\n",
            "\n",
            "\n",
            "confusion_matrix\n",
            " [[436  88]\n",
            " [ 58 418]]\n",
            "\n",
            "classification_report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.88      0.83      0.86       524\n",
            "    positive       0.83      0.88      0.85       476\n",
            "\n",
            "    accuracy                           0.85      1000\n",
            "   macro avg       0.85      0.86      0.85      1000\n",
            "weighted avg       0.86      0.85      0.85      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF Vectorization (ngram = (1,2))"
      ],
      "metadata": {
        "id": "ZWccTeH2HwXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline3 = Pipeline([\n",
        "    (\"vec\", TfidfVectorizer(ngram_range=(1, 2))),\n",
        "    (\"lr\", LogisticRegression())\n",
        "])\n",
        "\n",
        "pipeline3.fit(X_train, y_train)\n",
        "\n",
        "y3_pred = pipeline3.predict(X_test)\n",
        "\n",
        "print('accuracy_score', accuracy_score(y_test, y3_pred))\n",
        "print('\\n')\n",
        "\n",
        "print('confusion_matrix\\n',confusion_matrix(y_test, y3_pred))\n",
        "\n",
        "print('\\nclassification_report\\n',classification_report(y_test, y3_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIuD-2uaIAkz",
        "outputId": "f930d2ee-db75-4bef-9609-3ede6dffc6c9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy_score 0.855\n",
            "\n",
            "\n",
            "confusion_matrix\n",
            " [[444  80]\n",
            " [ 65 411]]\n",
            "\n",
            "classification_report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.85      0.86       524\n",
            "    positive       0.84      0.86      0.85       476\n",
            "\n",
            "    accuracy                           0.85      1000\n",
            "   macro avg       0.85      0.86      0.85      1000\n",
            "weighted avg       0.86      0.85      0.86      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without Stopwords"
      ],
      "metadata": {
        "id": "srKSSScVIH3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline4 = Pipeline([\n",
        "    (\"vec\", TfidfVectorizer(stop_words=stop, ngram_range=(1,2))),\n",
        "    (\"lr\", LogisticRegression())\n",
        "])\n",
        "\n",
        "pipeline4.fit(X_train, y_train)\n",
        "\n",
        "y4_pred = pipeline4.predict(X_test)\n",
        "\n",
        "print('accuracy_score', accuracy_score(y_test, y4_pred))\n",
        "print('\\n')\n",
        "\n",
        "print('confusion_matrix\\n',confusion_matrix(y_test, y4_pred))\n",
        "\n",
        "print('\\nclassification_report\\n',classification_report(y_test, y4_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PsgnvzYIIdR",
        "outputId": "e9034740-f19e-401d-b23d-5174f8f83665"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy_score 0.852\n",
            "\n",
            "\n",
            "confusion_matrix\n",
            " [[439  85]\n",
            " [ 63 413]]\n",
            "\n",
            "classification_report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.84      0.86       524\n",
            "    positive       0.83      0.87      0.85       476\n",
            "\n",
            "    accuracy                           0.85      1000\n",
            "   macro avg       0.85      0.85      0.85      1000\n",
            "weighted avg       0.85      0.85      0.85      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation"
      ],
      "metadata": {
        "id": "Plp9WitpIhr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_validation = [\"I enjoy watching it\", \"It's not good\"]\n",
        "\n",
        "print('pipeline1' ,pipeline1.predict(X_validation))\n",
        "print('\\n')\n",
        "\n",
        "print('pipeline2' ,pipeline2.predict(X_validation))\n",
        "print('\\n')\n",
        "\n",
        "print('pipeline3' ,pipeline3.predict(X_validation))\n",
        "print('\\n')\n",
        "\n",
        "print('pipeline4' ,pipeline4.predict(X_validation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dln59TwoIixL",
        "outputId": "5d9cbd71-4de4-46e7-88bc-aa305c3927da"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pipeline1 ['positive' 'positive']\n",
            "\n",
            "\n",
            "pipeline2 ['positive' 'positive']\n",
            "\n",
            "\n",
            "pipeline3 ['positive' 'negative']\n",
            "\n",
            "\n",
            "pipeline4 ['positive' 'positive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM"
      ],
      "metadata": {
        "id": "rxj3LWNNJYvF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CountVectorizer"
      ],
      "metadata": {
        "id": "sNWq9IVSJZ6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "_b-1geGJJcH9"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_svm1 = Pipeline([\n",
        "    (\"vec\", CountVectorizer()),\n",
        "    (\"svm\", SVC())\n",
        "])\n",
        "\n",
        "pipeline_svm1.fit(X_train, y_train)\n",
        "\n",
        "y1_pred = pipeline_svm1.predict(X_test)\n",
        "\n",
        "print('accuracy_score', accuracy_score(y_test, y1_pred))\n",
        "print('\\n')\n",
        "\n",
        "print('confusion_matrix\\n',confusion_matrix(y_test, y1_pred))\n",
        "\n",
        "print('\\nclassification_report\\n',classification_report(y_test, y1_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOZgVKOyKPAu",
        "outputId": "b9d56669-cdec-4a7d-e2eb-b1501654768e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy_score 0.806\n",
            "\n",
            "\n",
            "confusion_matrix\n",
            " [[401 123]\n",
            " [ 71 405]]\n",
            "\n",
            "classification_report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.85      0.77      0.81       524\n",
            "    positive       0.77      0.85      0.81       476\n",
            "\n",
            "    accuracy                           0.81      1000\n",
            "   macro avg       0.81      0.81      0.81      1000\n",
            "weighted avg       0.81      0.81      0.81      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF Vectorizer"
      ],
      "metadata": {
        "id": "nO6vZNoVKPYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_svm2 = Pipeline([\n",
        "    (\"vec\", TfidfVectorizer()),\n",
        "    (\"svm\", SVC())\n",
        "])\n",
        "\n",
        "pipeline_svm2.fit(X_train, y_train)\n",
        "\n",
        "y2_pred = pipeline_svm2.predict(X_test)\n",
        "\n",
        "print('accuracy_score', accuracy_score(y_test, y2_pred))\n",
        "print('\\n')\n",
        "\n",
        "print('confusion_matrix\\n',confusion_matrix(y_test, y2_pred))\n",
        "\n",
        "print('\\nclassification_report\\n',classification_report(y_test, y2_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDu3OXFjKQQJ",
        "outputId": "4bbd522b-fdd8-459f-9cdb-986c25ea5936"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy_score 0.869\n",
            "\n",
            "\n",
            "confusion_matrix\n",
            " [[447  77]\n",
            " [ 54 422]]\n",
            "\n",
            "classification_report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.89      0.85      0.87       524\n",
            "    positive       0.85      0.89      0.87       476\n",
            "\n",
            "    accuracy                           0.87      1000\n",
            "   macro avg       0.87      0.87      0.87      1000\n",
            "weighted avg       0.87      0.87      0.87      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF Vectorization (ngram = (1,2))"
      ],
      "metadata": {
        "id": "lKtXMWGbKQxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_svm3 = Pipeline([\n",
        "    (\"vec\", TfidfVectorizer(ngram_range=(1, 2))),\n",
        "    (\"svm\", SVC())\n",
        "])\n",
        "\n",
        "pipeline_svm3.fit(X_train, y_train)\n",
        "\n",
        "y3_pred = pipeline_svm3.predict(X_test)\n",
        "\n",
        "print('accuracy_score', accuracy_score(y_test, y3_pred))\n",
        "print('\\n')\n",
        "\n",
        "print('confusion_matrix\\n',confusion_matrix(y_test, y3_pred))\n",
        "\n",
        "print('\\nclassification_report\\n',classification_report(y_test, y3_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCA6KNq6KRgm",
        "outputId": "118d4cf6-3918-4256-db31-2e8f7fad2858"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy_score 0.855\n",
            "\n",
            "\n",
            "confusion_matrix\n",
            " [[437  87]\n",
            " [ 58 418]]\n",
            "\n",
            "classification_report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.88      0.83      0.86       524\n",
            "    positive       0.83      0.88      0.85       476\n",
            "\n",
            "    accuracy                           0.85      1000\n",
            "   macro avg       0.86      0.86      0.85      1000\n",
            "weighted avg       0.86      0.85      0.86      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without Stopwords"
      ],
      "metadata": {
        "id": "AEuGEiu_KR-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_svm4 = Pipeline([\n",
        "    (\"vec\", TfidfVectorizer(stop_words=stop, ngram_range=(1,2))),\n",
        "    (\"svm\", SVC())\n",
        "])\n",
        "\n",
        "pipeline_svm4.fit(X_train, y_train)\n",
        "\n",
        "y4_pred = pipeline_svm4.predict(X_test)\n",
        "\n",
        "print('accuracy_score', accuracy_score(y_test, y4_pred))\n",
        "print('\\n')\n",
        "\n",
        "print('confusion_matrix\\n',confusion_matrix(y_test, y4_pred))\n",
        "\n",
        "print('\\nclassification_report\\n',classification_report(y_test, y4_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfcpYnOeKS0O",
        "outputId": "0f6cf347-39e8-4d65-d89a-e85702405a3b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy_score 0.85\n",
            "\n",
            "\n",
            "confusion_matrix\n",
            " [[434  90]\n",
            " [ 60 416]]\n",
            "\n",
            "classification_report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.88      0.83      0.85       524\n",
            "    positive       0.82      0.87      0.85       476\n",
            "\n",
            "    accuracy                           0.85      1000\n",
            "   macro avg       0.85      0.85      0.85      1000\n",
            "weighted avg       0.85      0.85      0.85      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation"
      ],
      "metadata": {
        "id": "7L6onqF6KTii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_validation = [\"I enjoy watching it\", \"It's not good\"]\n",
        "\n",
        "print('pipeline_svm1' ,pipeline_svm1.predict(X_validation))\n",
        "print('\\n')\n",
        "\n",
        "print('pipeline_svm2' ,pipeline_svm2.predict(X_validation))\n",
        "print('\\n')\n",
        "\n",
        "print('pipeline_svm3' ,pipeline_svm3.predict(X_validation))\n",
        "print('\\n')\n",
        "\n",
        "print('pipeline_svm4' ,pipeline_svm4.predict(X_validation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a74kappMKUql",
        "outputId": "0e6103a2-4057-465c-d23c-3e38ad61bd99"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pipeline_svm1 ['positive' 'positive']\n",
            "\n",
            "\n",
            "pipeline_svm2 ['positive' 'positive']\n",
            "\n",
            "\n",
            "pipeline_svm3 ['positive' 'negative']\n",
            "\n",
            "\n",
            "pipeline_svm4 ['positive' 'positive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost"
      ],
      "metadata": {
        "id": "l6q9w8ZXLDv4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CountVectorizer"
      ],
      "metadata": {
        "id": "L2Q6fMGLLHGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "YfO61k84LJ-t"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()"
      ],
      "metadata": {
        "id": "jSk-lpAON0yu"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "\n",
        "y_test_encoded = label_encoder.transform(y_test)"
      ],
      "metadata": {
        "id": "YA1VPVUAN5uM"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train_encoded\n",
        "\n",
        "y_test = y_test_encoded"
      ],
      "metadata": {
        "id": "SNyIVQvsOCUO"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_xgb1 = Pipeline([\n",
        "    (\"vec\", CountVectorizer()),\n",
        "    (\"xgb\", XGBClassifier())\n",
        "])\n",
        "\n",
        "pipeline_xgb1.fit(X_train, y_train)\n",
        "\n",
        "y1_pred = pipeline_xgb1.predict(X_test)\n",
        "\n",
        "print('accuracy_score', accuracy_score(y_test, y1_pred))\n",
        "print('\\n')\n",
        "\n",
        "print('confusion_matrix\\n',confusion_matrix(y_test, y1_pred))\n",
        "\n",
        "print('\\nclassification_report\\n',classification_report(y_test, y1_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86SE2pXwMhKm",
        "outputId": "e24af77a-1a6a-4a39-ac59-4b1c2efc8104"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy_score 0.831\n",
            "\n",
            "\n",
            "confusion_matrix\n",
            " [[420 104]\n",
            " [ 65 411]]\n",
            "\n",
            "classification_report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.80      0.83       524\n",
            "           1       0.80      0.86      0.83       476\n",
            "\n",
            "    accuracy                           0.83      1000\n",
            "   macro avg       0.83      0.83      0.83      1000\n",
            "weighted avg       0.83      0.83      0.83      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF Vectorizer"
      ],
      "metadata": {
        "id": "kqhX8XjvMhk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_xgb2 = Pipeline([\n",
        "    (\"vec\", TfidfVectorizer()),\n",
        "    (\"xgb\", XGBClassifier())\n",
        "])\n",
        "\n",
        "pipeline_xgb2.fit(X_train, y_train)\n",
        "\n",
        "y2_pred = pipeline_xgb2.predict(X_test)\n",
        "\n",
        "print('accuracy_score', accuracy_score(y_test, y2_pred))\n",
        "print('\\n')\n",
        "\n",
        "print('confusion_matrix\\n',confusion_matrix(y_test, y2_pred))\n",
        "\n",
        "print('\\nclassification_report\\n',classification_report(y_test, y2_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cS2Tw2rMqvC",
        "outputId": "31931c4c-9dcd-428b-e5ab-7a222c32bb9e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy_score 0.812\n",
            "\n",
            "\n",
            "confusion_matrix\n",
            " [[419 105]\n",
            " [ 83 393]]\n",
            "\n",
            "classification_report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.80      0.82       524\n",
            "           1       0.79      0.83      0.81       476\n",
            "\n",
            "    accuracy                           0.81      1000\n",
            "   macro avg       0.81      0.81      0.81      1000\n",
            "weighted avg       0.81      0.81      0.81      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF Vectorization (ngram = (1,2))"
      ],
      "metadata": {
        "id": "lP7jk8XRMrA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_xgb3 = Pipeline([\n",
        "    (\"vec\", TfidfVectorizer(ngram_range=(1, 2))),\n",
        "    (\"xgb\", XGBClassifier())\n",
        "])\n",
        "\n",
        "pipeline_xgb3.fit(X_train, y_train)\n",
        "\n",
        "y3_pred = pipeline_xgb3.predict(X_test)\n",
        "\n",
        "print('accuracy_score', accuracy_score(y_test, y3_pred))\n",
        "print('\\n')\n",
        "\n",
        "print('confusion_matrix\\n',confusion_matrix(y_test, y3_pred))\n",
        "\n",
        "print('\\nclassification_report\\n',classification_report(y_test, y3_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sws9k5b9Mr0d",
        "outputId": "f67b2d2c-6b2d-42c6-f417-6dc5fce2d06d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy_score 0.835\n",
            "\n",
            "\n",
            "confusion_matrix\n",
            " [[431  93]\n",
            " [ 72 404]]\n",
            "\n",
            "classification_report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.82      0.84       524\n",
            "           1       0.81      0.85      0.83       476\n",
            "\n",
            "    accuracy                           0.83      1000\n",
            "   macro avg       0.83      0.84      0.83      1000\n",
            "weighted avg       0.84      0.83      0.84      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without Stopwords"
      ],
      "metadata": {
        "id": "9-yxf0kSMsNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_xgb4 = Pipeline([\n",
        "    (\"vec\", TfidfVectorizer(stop_words=stop, ngram_range=(1,2))),\n",
        "    (\"xgb\", XGBClassifier())\n",
        "])\n",
        "\n",
        "pipeline_xgb4.fit(X_train, y_train)\n",
        "\n",
        "y4_pred = pipeline_xgb4.predict(X_test)\n",
        "\n",
        "print('accuracy_score', accuracy_score(y_test, y4_pred))\n",
        "print('\\n')\n",
        "\n",
        "print('confusion_matrix\\n',confusion_matrix(y_test, y4_pred))\n",
        "\n",
        "print('\\nclassification_report\\n',classification_report(y_test, y4_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXAvElxAMtOr",
        "outputId": "0afb2589-cc29-4f48-d3f8-b040fe978523"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy_score 0.823\n",
            "\n",
            "\n",
            "confusion_matrix\n",
            " [[428  96]\n",
            " [ 81 395]]\n",
            "\n",
            "classification_report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.82      0.83       524\n",
            "           1       0.80      0.83      0.82       476\n",
            "\n",
            "    accuracy                           0.82      1000\n",
            "   macro avg       0.82      0.82      0.82      1000\n",
            "weighted avg       0.82      0.82      0.82      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation"
      ],
      "metadata": {
        "id": "v8ExpRtGMtno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_validation = [\"I enjoy watching it\", \"It's not good\"]\n",
        "\n",
        "print('pipeline_xgb1' ,pipeline_xgb1.predict(X_validation))\n",
        "print('\\n')\n",
        "\n",
        "print('pipeline_xgb2' ,pipeline_xgb2.predict(X_validation))\n",
        "print('\\n')\n",
        "\n",
        "print('pipeline_xgb3' ,pipeline_xgb3.predict(X_validation))\n",
        "print('\\n')\n",
        "\n",
        "print('pipeline_xgb4' ,pipeline_xgb4.predict(X_validation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYIUI1UfMuhe",
        "outputId": "5d5818d4-76ff-406d-c397-81144d55c306"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pipeline_xgb1 [1 1]\n",
            "\n",
            "\n",
            "pipeline_xgb2 [1 1]\n",
            "\n",
            "\n",
            "pipeline_xgb3 [1 1]\n",
            "\n",
            "\n",
            "pipeline_xgb4 [1 1]\n"
          ]
        }
      ]
    }
  ]
}